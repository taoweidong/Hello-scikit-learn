# src/trainer.py
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score
from loguru import logger
import pandas as pd
import joblib
from config import DATA_PATH, LATEST_MODEL_PATH, get_timestamped_model_path


class ModelTrainer:
    """
    æ•æ„Ÿä¿¡æ¯åˆ†ç±»æ¨¡å‹è®­ç»ƒå™¨
    è´Ÿè´£åŠ è½½æ•°æ®ã€è®­ç»ƒã€è¯„ä¼°å’Œä¿å­˜æ¨¡å‹
    """

    def __init__(self):
        self.pipeline = None
        self.X_test = None
        self.y_test = None
        logger.info("ModelTrainer åˆå§‹åŒ–å®Œæˆ")

    def load_data(self):
        """åŠ è½½å¹¶æ¸…æ´—è®­ç»ƒæ•°æ®"""
        try:
            logger.info(f"æ­£åœ¨åŠ è½½æ•°æ®: {DATA_PATH}")
            df = pd.read_excel(DATA_PATH)
            logger.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸï¼Œå…± {len(df)} æ¡è®°å½•")

            # æ¸…æ´—
            df.dropna(subset=['text', 'is_sensitive'], inplace=True)
            logger.debug(f"æ•°æ®æ¸…æ´—å®Œæˆï¼Œå‰©ä½™ {len(df)} æ¡æœ‰æ•ˆæ•°æ®")

            return df['text'].astype(str), df['is_sensitive']
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise

    def build_pipeline(self):
        """æ„å»ºæœºå™¨å­¦ä¹  Pipeline"""
        self.pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=5000)),
            ('classifier', MultinomialNB())
        ])
        logger.info("Pipeline æ„å»ºå®Œæˆ: TF-IDF + æœ´ç´ è´å¶æ–¯")

    def train(self):
        """è®­ç»ƒæ¨¡å‹"""
        X, y = self.load_data()
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        self.build_pipeline()
        logger.info("å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        self.pipeline.fit(X_train, y_train)

        # ä¿ç•™æµ‹è¯•é›†ç”¨äºè¯„ä¼°
        self.X_test = X_test
        self.y_test = y_test

        logger.success("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

    def evaluate(self):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        if not self.pipeline or self.X_test is None:
            logger.warning("âš ï¸ æ¨¡å‹æœªè®­ç»ƒæˆ–æµ‹è¯•é›†ä¸ºç©ºï¼Œè·³è¿‡è¯„ä¼°")
            return None

        y_pred = self.pipeline.predict(self.X_test)
        acc = accuracy_score(self.y_test, y_pred)

        logger.info(f"ğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœ:")
        logger.info(f"   å‡†ç¡®ç‡: {acc:.4f}")
        logger.info("\n" + classification_report(self.y_test, y_pred, target_names=['éæ•æ„Ÿ', 'æ•æ„Ÿ'],
                                                 zero_division=0  # å¯é€‰ï¼š0, 1, 'warn'ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
                                                 ))

        return acc

    def save_model(self):
        """ä¿å­˜æ¨¡å‹åˆ°æ–‡ä»¶ç³»ç»Ÿ"""
        try:
            # ä¿å­˜å¸¦æ—¶é—´æˆ³çš„ç‰ˆæœ¬
            timestamped_path = get_timestamped_model_path()
            joblib.dump(self.pipeline, timestamped_path)
            logger.info(f"ğŸ“ æ¨¡å‹å·²ä¿å­˜ï¼ˆå†å²ç‰ˆæœ¬ï¼‰: {timestamped_path}")

            # ä¿å­˜ä¸ºæœ€æ–°ç‰ˆ
            joblib.dump(self.pipeline, LATEST_MODEL_PATH)
            logger.success(f"âœ… æ¨¡å‹å·²æ›´æ–°è‡³æœ€æ–°ç‰ˆ: {LATEST_MODEL_PATH}")

        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ä¿å­˜å¤±è´¥: {e}")
            raise
